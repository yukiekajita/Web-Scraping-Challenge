{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splinter import Browser\n",
    "from splinter.exceptions import ElementDoesNotExist\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/bin/chromedriver\r\n"
     ]
    }
   ],
   "source": [
    "# https://splinter.readthedocs.io/en/latest/drivers/chrome.html\n",
    "!which chromedriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##executable_path = {'executable_path': '/usr/local/bin/chromedriver'}\n",
    "browser = Browser('chrome', headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NASA Mars News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasa_url = 'http://mars.nasa.gov/news/'\n",
    "browser.visit(nasa_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NASA Readies Perseverance Mars Rover's Earthly Twin \n",
      "Did you know NASA's next Mars rover has a nearly identical sibling on Earth for testing? Even better, it's about to roll for the first time through a replica Martian landscape.\n"
     ]
    }
   ],
   "source": [
    "# HTML object\n",
    "html = browser.html\n",
    "\n",
    "# Parse HTML with Beautiful Soup\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Retrieve all elements that contain title and paragrapg\n",
    "news_articles = soup.find('div', class_='list_text')\n",
    "#for news in news_articles:\n",
    "news_title = news_articles.find('div', class_='content_title').text\n",
    "news_paragraph = news_articles.find('div', class_='article_teaser_body').text\n",
    "\n",
    "#print('---------------------')\n",
    "print(news_title)\n",
    "print(news_paragraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JPL Mars Space Images - Featured Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "browser = Browser('chrome', headless=False)\n",
    "\n",
    "spaceimage_url = 'http://www.jpl.nasa.gov/spaceimages/?search=&category-Mars'\n",
    "browser.visit(spaceimage_url)\n",
    "\n",
    "# Go to Full Image by click the button\n",
    "browser.click_link_by_partial_text('FULL IMAGE')\n",
    "time.sleep(5)\n",
    "\n",
    "# Go to More Info by click the button\n",
    "browser.click_link_by_partial_text('more info')\n",
    "\n",
    "# Parse HTML with Beautiful Soup\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Scrape the URL images with href info\n",
    "image_url = soup.find('figure', class_='lede').a['href']\n",
    "featured_image_url = f'https://www.jpl.nasa.gov{image_url}'\n",
    "print(featured_image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = Browser('chrome', headless=False)\n",
    "facts_url = 'http://space-facts.com/mars/'\n",
    "browser.visit(facts_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Pandas to scrape the table containing facts about Mars Planet Profile\n",
    "table = pd.read_html(facts_url)\n",
    "mars_facts = table[0]\n",
    "print(mars_facts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns\n",
    "mars_facts.columns = ['Description', 'Mars'] \n",
    "print(mars_facts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index\n",
    "mars_facts.set_index('Description', inplace=True)\n",
    "print(mars_facts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pandas to convert the data to a HTML table string\n",
    "html_table = mars_facts.to_html\n",
    "#html_table = html_table.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = Browser('chrome', headless=False)\n",
    "hemisphere_url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "browser.visit(hemisphere_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through all pages: 50 pages on the website\n",
    "hemisphere_html = browser.html\n",
    "# Parse HTML with Beautiful Soup\n",
    "hemisphere_soup = BeautifulSoup(hemisphere_html, 'html.parser')\n",
    "\n",
    "# Create a dictionary to store titles and image links\n",
    "hemisphere_image_urls = []\n",
    "\n",
    "# Retrieve all elements that contain book information\n",
    "hemispheres = hemisphere_soup.find_all('div', class_='item')\n",
    "\n",
    "# Iterate through each image\n",
    "for hemisphere in hemispheres:\n",
    "    \n",
    "    # Find title with h3\n",
    "    title = hemisphere.find(\"h3\").text\n",
    "    # Remove 'Enhanced' from the h3 title\n",
    "    title = title.replace(\"Enhanced\", \"\")\n",
    "    \n",
    "    # Collect image link name and browser visit each mars name link\n",
    "    end_link_name = hemisphere.find(\"a\")[\"href\"]\n",
    "    image_link = \"https://astrogeology.usgs.gov/\" + end_link_name   \n",
    "    browser.visit(image_link)\n",
    "    \n",
    "    # Then grab the 'Sample' full jpg image under class 'downloads' \n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    downloads = soup.find(\"div\", class_=\"downloads\")\n",
    "    # Collect the image href for image_url\n",
    "    image_url = downloads.find(\"a\")[\"href\"]\n",
    "    hemisphere_image_urls.append({\"title\": title, \"img_url\": image_url})\n",
    "\n",
    "# Print image title and url\n",
    "print(hemisphere_image_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put together all scraped info as mars_data\n",
    "mars_data = {\n",
    "    \"News_Title\": news_title,\n",
    "    \"News_Paragraph\": news_paragraph,\n",
    "    \"Featured_Image\": featured_image_url,\n",
    "    \"Mars_Facts\": html_table,\n",
    "    \"Mars_Hemisphere_Image\": hemisphere_image_urls\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## I slightly modified the script above in scrape_mars.py when I had errors when I run the file in python##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
